# import necessary packages for hand gesture recognition project using Python OpenCV
import cv2
import numpy as np
import mediapipe as mp
import tensorflow as tf
from tensorflow.keras.models import load_model
import streamlit as st

# initialize mediapipe
mpHands = mp.solutions.hands
hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mpDraw = mp.solutions.drawing_utils

# load the model
model = load_model("keras_model.h5")

# define the labels
labels = ["A", "B", "C", "D", "E", "F", "G", "H", "I", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y"]

# create a streamlit app
st.title("Deteksi Gestur Tangan SIBI")
st.header("Aplikasi web untuk mengklasifikasikan gestur tangan Sistem Isyarat Bahasa Indonesia (SIBI)")
st.write("Aplikasi ini menggunakan model Convolutional Neural Network (CNN) yakni InceptionV3 yang dilatih dengan kerangka kerja Teachable Machine dan pustaka MediaPipe untuk mendeteksi dan mengenali isyarat tangan dari SIBI. Aplikasi ini dapat mengklasifikasikan 24 isyarat tangan dari A hingga Y, kecuali J dan Z.")

# create a sidebar
st.sidebar.title("Menu")
st.sidebar.write("Pilih menu untuk ditampilkan :")
option = st.sidebar.radio("", ["Lihat Contoh", "Pakai Kamera"])

# if the user chooses to see an example
if option == "Lihat Contoh":
    # display an image of a hand gesture
    st.subheader("Contoh")
    st.write("Berikut ini contoh isyarat tangan yang mewakili huruf A :")
    image = cv2.imread("./A/A1.jpg")
    st.image(image, channels="BGR")
    # preprocess the image
    image = cv2.resize(image, (224, 224))
    image = image / 255.0
    image = np.expand_dims(image, axis=0)
    # predict the label
    prediction = model.predict(image)
    label = labels[np.argmax(prediction)]
    # display the prediction
    st.subheader("Prediksi")
    st.write(f"Label yang diprediksi adalah : {label}")
    st.write(f"Skor kepercayaannya adalah : {np.max(prediction)}")

# if the user chooses to use webcam
elif option == "Pakai Kamera":
    # display a webcam feed
    st.subheader("Webcam Feed")
    st.write("Izinkan aplikasi untuk mengakses kamera Anda")
    # create a placeholder for the webcam feed
    placeholder = st.empty()
    # open the webcam
    cap = cv2.VideoCapture(0)
    # loop over the frames
    while True:
        # read a frame
        success, frame = cap.read()
        if not success:
            break
        # flip the frame horizontally
        frame = cv2.flip(frame, 1)
        # convert the frame to RGB
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        # get the height and width of the frame
        h, w, c = frame.shape
        # copy the frame
        frame_copy = frame.copy()
        # process the frame with mediapipe
        results = hands.process(frame)
        # check if a hand is detected
        if results.multi_hand_landmarks:
            # get the hand landmarks
            hand_landmarks = results.multi_hand_landmarks[0]
            # draw the hand landmarks
            mpDraw.draw_landmarks(frame, hand_landmarks, mpHands.HAND_CONNECTIONS)
            # get the bounding box coordinates
            x_min = min([landmark.x for landmark in hand_landmarks.landmark]) * w
            x_max = max([landmark.x for landmark in hand_landmarks.landmark]) * w
            y_min = min([landmark.y for landmark in hand_landmarks.landmark]) * h
            y_max = max([landmark.y for landmark in hand_landmarks.landmark]) * h
            x_min = int(x_min)
            x_max = int(x_max)
            y_min = int(y_min)
            y_max = int(y_max)
            # crop the hand region
            hand_region = frame_copy[y_min:y_max, x_min:x_max]
            # check if the hand region is not empty
            if hand_region.size != 0:
                # resize the hand region
                hand_region = cv2.resize(hand_region, (224, 224))
                # preprocess the hand region
                hand_region = hand_region / 255.0
                hand_region = np.expand_dims(hand_region, axis=0)
                # predict the label
                prediction = model.predict(hand_region)
                label = labels[np.argmax(prediction)]
                # display the label and the confidence score
                cv2.putText(frame, label, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
                cv2.putText(frame, f"{np.max(prediction):.2f}", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        # update the webcam feed
        placeholder.image(frame, channels="RGB")
    # release the webcam
    cap.release()